# ğŸš€ Crypto Sentiment API

Une API permettant d'interagir avec le scraping de donnÃ©es financiÃ¨res, l'analyse de sentiment via **CryptoBERT** et la gestion des donnÃ©es cryptos.

## ğŸ“– Table des matiÃ¨res
- [ğŸ“Œ PrÃ©sentation](#-prÃ©sentation)
- [âš™ï¸ Installation](#%EF%B8%8F-installation)
- [ğŸš€ Lancer l'API](#-lancer-lapi)
- [ğŸ› ï¸ FonctionnalitÃ©s](#%EF%B8%8F-fonctionnalitÃ©s)
- [ğŸ“‚ Structure du Projet](#-structure-du-projet)
- [ğŸ“¡ Endpoints de l'API](#-endpoints-de-lapi)
- [ğŸ“Œ Notes Importantes](#-notes-importantes)

---

## ğŸ“Œ PrÃ©sentation

Ce projet a pour objectif :

ğŸ“Š Scraper des actualitÃ©s cryptos depuis plusieurs sources.
ğŸ” Analyser le sentiment du marchÃ© Ã  l'aide du modÃ¨le CryptoBERT.
ğŸ“ˆ Calculer les rendements associÃ©s aux stratÃ©gies de trading.
Nous avons scrapÃ© des donnÃ©es depuis Reddit et CryptoNews, mais seules les donnÃ©es de CryptoNews ont Ã©tÃ© utilisÃ©es pour l'analyse des sentiments et les modÃ¨les de prÃ©diction. ğŸ“°âš¡

---

## âš™ï¸ Installation

### 1ï¸âƒ£ **Cloner le projet**
```bash
git clone https://github.com/KADA-SEDODE/crypto_sentiment.git
cd crypto-sentiment-api


2ï¸âƒ£ CrÃ©er un environnement virtuel

python -m venv .venv
source .venv/bin/activate  # Pour Linux/macOS
# ou
.venv\Scripts\activate  # Pour Windows
3ï¸âƒ£ Installer les dÃ©pendances
pip install -r requirements.txt

ğŸš€ Lancer l'API
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload

## ğŸ“‚ Structure du Projet

ğŸ“¦ **PROJET_FINANCE_QUANTITATIVE**
â”œâ”€â”€ ğŸ“‚ .venv                      # Environnement virtuel Python
â”œâ”€â”€ ğŸ“‚ data
â”‚   â”œâ”€â”€ ğŸ“‚ raw                    # DonnÃ©es brutes scrappÃ©es
â”‚   â”œâ”€â”€ ğŸ“‚ reddit_data            # DonnÃ©es spÃ©cifiques Ã  Reddit
â”œâ”€â”€ ğŸ“‚ data_processing
â”‚   â”œâ”€â”€ ğŸ“‚ data
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_cleaning copy.ipynb  # Notebook de nettoyage et preprocessing
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ df_final.csv          # DonnÃ©es finales aprÃ¨s preprocessing
â”‚   â”œâ”€â”€ ğŸ“‚ scripts                 # Scripts de traitement des donnÃ©es
â”‚       â”œâ”€â”€ ğŸ“‚ __pycache__/          # Cache Python
â”œâ”€â”€ ğŸ“‚ src                         # Code source principal
â”‚   â”œâ”€â”€ ğŸ“‚ api                     # API FastAPI
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ __pycache__/         # Cache Python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          # Initialisation du module API
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ data_api.py          # API pour l'analyse des donnÃ©es et des sentiments
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ main.py              # Point d'entrÃ©e principal de l'API
â”‚   â”‚   â”œâ”€â”€ ğŸ“„predict_api.py           # ğŸ¤– API pour analyser les sentiments avec CryptoBERT
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ models.py            # ModÃ¨les Pydantic pour les requÃªtes/rÃ©ponses
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scraper_api.py       # API pour le scraping des news cryptos
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ utils.py             # Fonctions utilitaires
â”‚   â”œâ”€â”€ ğŸ“‚ scraping                 # Scripts de scraping
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ __pycache__/         # Cache Python
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py          # Initialisation du module scraping
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ crypto_prices.py     # RÃ©cupÃ©ration des prix des cryptos
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ reddit_articles.py   # Extraction des articles Reddit
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ reddit_scraper.py    # Scraping depuis Reddit
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ scraping_5cryptos.py # Scraping de 5 cryptos depuis crypto.news
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ utils.py             # Fonctions utilitaires scraping
â”œâ”€â”€ ğŸ“„ .gitignore                   # Fichiers Ã  ignorer par Git
â”œâ”€â”€ ğŸ“„ README.md                    # Documentation du projet ğŸ“–
â”œâ”€â”€ ğŸ“„ requirements.txt              # Liste des dÃ©pendances Python ğŸ“œ


ğŸ“Œ Notes Importantes
ğŸ“ Les fichiers de donnÃ©es utiles pour l'API sont dÃ©jÃ  disponibles dans data/raw/ âœ…
â¡ï¸ Pas besoin d'exÃ©cuter data_cleaning_v2.ipynb, qui peut Ãªtre trÃ¨s long ! âš ï¸
âš¡ Le scraping doit Ãªtre exÃ©cutÃ© avant dâ€™analyser les sentiments.
ğŸ”„ Si des erreurs surviennent, rÃ©installe les dÃ©pendances avec : pip install -r requirements.txt
