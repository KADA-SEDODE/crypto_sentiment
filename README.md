# ğŸš€ Crypto Sentiment API

Une API permettant d'interagir avec le scraping de donnÃ©es financiÃ¨res, l'analyse de sentiment via **CryptoBERT** et la gestion des donnÃ©es cryptos.

## ğŸ“– Table des matiÃ¨res
- [ğŸ“Œ PrÃ©sentation](#-prÃ©sentation)
- [âš™ï¸ Installation](#%EF%B8%8F-installation)
- [ğŸš€ Lancer l'API](#-lancer-lapi)
- [ğŸ› ï¸ FonctionnalitÃ©s](#%EF%B8%8F-fonctionnalitÃ©s)
- [ğŸ“‚ Structure du Projet](#-structure-du-projet)
- [ğŸ“¡ Endpoints de l'API](#-endpoints-de-lapi)
- [ğŸ“Œ Notes Importantes](#-notes-importantes)

---

## ğŸ“Œ PrÃ©sentation

Ce projet a pour objectif de scraper des actualitÃ©s cryptos, d'analyser le **sentiment du marchÃ©** et de calculer les **rendements** associÃ©s aux stratÃ©gies de trading.

---

## âš™ï¸ Installation

### 1ï¸âƒ£ **Cloner le projet**

git clone https://github.com/KADA-SEDODE/crypto_sentiment.git
cd crypto-sentiment-api


2ï¸âƒ£ CrÃ©er un environnement virtuel

python -m venv .venv
source .venv/bin/activate  # Pour Linux/macOS
# ou
.venv\Scripts\activate  # Pour Windows
3ï¸âƒ£ Installer les dÃ©pendances
pip install -r requirements.txt

ğŸš€ Lancer l'API
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload

ğŸ“¦ ğŸ“Œ Structure du Projet**

ğŸ“¦ PROJET_FINANCE_QUANTITATIVE
â”œâ”€â”€ ğŸ“‚ .venv                      # Environnement virtuel Python
â”œâ”€â”€ ğŸ“‚ data
â”‚   â”œâ”€â”€ ğŸ“‚ raw                    # DonnÃ©es brutes scrappÃ©es
â”‚   â”œâ”€â”€ ğŸ“‚ reddit_data            # DonnÃ©es spÃ©cifiques Ã  Reddit
â”œâ”€â”€ ğŸ“‚ data_processing
â”‚   â”œâ”€â”€ ğŸ“‚ data
â”‚   â”‚   â”œâ”€â”€ data_cleaning copy.ipynb  # Notebook de nettoyage et preprocessing
â”‚   â”‚   â”œâ”€â”€ df_final.csv          # DonnÃ©es finales aprÃ¨s preprocessing
â”‚   â”œâ”€â”€ ğŸ“‚ scripts                 # Contiendra les scripts de traitement des donnÃ©es
â”‚       â”œâ”€â”€ __pycache__/          # Cache Python
â”œâ”€â”€ ğŸ“‚ src                         # Code source principal
â”‚   â”œâ”€â”€ ğŸ“‚ api                     # API FastAPI
â”‚   â”‚   â”œâ”€â”€ __pycache__/           # Cache Python
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Initialisation du module API
â”‚   â”‚   â”œâ”€â”€ data_api.py            # API pour l'analyse des donnÃ©es et des sentiments
â”‚   â”‚   â”œâ”€â”€ main.py                # Point d'entrÃ©e principal de l'API
â”‚   â”‚   â”œâ”€â”€ models.py              # ModÃ¨les Pydantic pour les requÃªtes/rÃ©ponses
â”‚   â”‚   â”œâ”€â”€ scraper_api.py         # API pour le scraping des news cryptos
â”‚   â”‚   â”œâ”€â”€ utils.py               # Fonctions utilitaires
â”‚   â”œâ”€â”€ ğŸ“‚ scraping                 # Scripts de scraping
â”‚   â”‚   â”œâ”€â”€ __pycache__/           # Cache Python
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Initialisation du module scraping
â”‚   â”‚   â”œâ”€â”€ crypto_prices.py       # RÃ©cupÃ©ration des prix des cryptos
â”‚   â”‚   â”œâ”€â”€ reddit_articles.py     # Extraction des articles Reddit
â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py      # Scraping depuis Reddit
â”‚   â”‚   â”œâ”€â”€ scraping_5cryptos.py   # Scraping de 5 cryptos depuis crypto.news
â”‚   â”‚   â”œâ”€â”€ utils.py               # Fonctions utilitaires scraping
â”œâ”€â”€ .gitignore                     # Fichiers Ã  ignorer par Git
â”œâ”€â”€ README.md                      # Documentation du projet ğŸ“–
â”œâ”€â”€ requirements.txt                # Liste des dÃ©pendances Python ğŸ“œ

### ğŸ“Œ Notes Importantes

ğŸ“‚ Les fichiers de donnÃ©es sont stockÃ©s dans data/raw/ et sont utilisÃ©s pour lâ€™analyse.
âš¡ Le scraping doit Ãªtre exÃ©cutÃ© avant dâ€™analyser les sentiments.
ğŸ”„ Si des erreurs surviennent, rÃ©installe les dÃ©pendances avec : pip install -r requirements.txt


